#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³ ë„í™”ëœ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
í‚¤ì›€ API ê¸°ë°˜ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ ì‹œìŠ¤í…œ
"""

import sys
import time
import threading
import queue
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from collections import defaultdict, deque
from typing import Dict, List, Tuple, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import asyncio
import aiohttp
from loguru import logger

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from kiwoom_api import KiwoomAPI, RealDataType
from error_handler import ErrorType, ErrorLevel, handle_error, retry_operation
from system_monitor import system_monitor, record_api_call, record_data_processed
from config import KIWOOM_CONFIG

@dataclass
class RealTimeData:
    """ì‹¤ì‹œê°„ ë°ì´í„° êµ¬ì¡°ì²´"""
    code: str
    name: str
    current_price: float
    change_rate: float
    volume: int
    amount: int
    open_price: float
    high_price: float
    low_price: float
    prev_close: float
    timestamp: datetime
    data_type: str
    additional_data: Dict = None

@dataclass
class DataCollectionConfig:
    """ë°ì´í„° ìˆ˜ì§‘ ì„¤ì •"""
    update_interval: float = 1.0  # ì´ˆ
    max_queue_size: int = 10000
    cache_duration: int = 300  # ì´ˆ
    retry_attempts: int = 3
    retry_delay: float = 1.0
    enable_compression: bool = True
    enable_caching: bool = True
    enable_monitoring: bool = True

class DataProcessor:
    """ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.processors = {
            'price_alert': self._process_price_alert,
            'volume_analysis': self._process_volume_analysis,
            'trend_analysis': self._process_trend_analysis,
            'volatility_calculation': self._process_volatility_calculation
        }
        
    def process_data(self, data: RealTimeData, processors: List[str] = None) -> Dict:
        """ë°ì´í„° ì²˜ë¦¬"""
        if processors is None:
            processors = list(self.processors.keys())
            
        results = {}
        for processor_name in processors:
            if processor_name in self.processors:
                try:
                    results[processor_name] = self.processors[processor_name](data)
                except Exception as e:
                    handle_error(
                        ErrorType.DATA_PROCESSING,
                        f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {processor_name}",
                        exception=e,
                        error_level=ErrorLevel.WARNING
                    )
                    results[processor_name] = None
                    
        return results
    
    def _process_price_alert(self, data: RealTimeData) -> Dict:
        """ê°€ê²© ì•Œë¦¼ ì²˜ë¦¬"""
        alerts = []
        
        # ê¸‰ë“±/ê¸‰ë½ ê°ì§€
        if abs(data.change_rate) > 5.0:
            alerts.append({
                'type': 'price_volatility',
                'message': f"{data.name} ê¸‰ê²©í•œ ê°€ê²© ë³€ë™: {data.change_rate:+.2f}%",
                'severity': 'high' if abs(data.change_rate) > 10.0 else 'medium'
            })
            
        return {'alerts': alerts}
    
    def _process_volume_analysis(self, data: RealTimeData) -> Dict:
        """ê±°ë˜ëŸ‰ ë¶„ì„"""
        # ê±°ë˜ëŸ‰ ê¸‰ì¦ ê°ì§€ (ì„ì‹œ ê¸°ì¤€)
        volume_ratio = data.volume / max(data.amount / data.current_price, 1)
        
        return {
            'volume_ratio': volume_ratio,
            'volume_signal': 'high' if volume_ratio > 2.0 else 'normal'
        }
    
    def _process_trend_analysis(self, data: RealTimeData) -> Dict:
        """ì¶”ì„¸ ë¶„ì„"""
        # ê°„ë‹¨í•œ ì¶”ì„¸ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ì´ì „ ë°ì´í„°ì™€ ë¹„êµ í•„ìš”)
        trend = 'up' if data.change_rate > 0 else 'down'
        
        return {
            'trend': trend,
            'strength': abs(data.change_rate) / 10.0  # 0-1 ë²”ìœ„
        }
    
    def _process_volatility_calculation(self, data: RealTimeData) -> Dict:
        """ë³€ë™ì„± ê³„ì‚°"""
        # ì¼ì¼ ë³€ë™ì„± (ê³ ê°€-ì €ê°€)
        daily_volatility = (data.high_price - data.low_price) / data.prev_close * 100
        
        return {
            'daily_volatility': daily_volatility,
            'volatility_level': 'high' if daily_volatility > 5.0 else 'normal'
        }

class DataCache:
    """ë°ì´í„° ìºì‹œ ê´€ë¦¬"""
    
    def __init__(self, max_size: int = 1000, ttl: int = 300):
        self.max_size = max_size
        self.ttl = ttl
        self.cache = {}
        self.timestamps = {}
        self.lock = threading.Lock()
        
    def get(self, key: str) -> Optional[RealTimeData]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self.lock:
            if key in self.cache:
                # TTL í™•ì¸
                if time.time() - self.timestamps[key] < self.ttl:
                    return self.cache[key]
                else:
                    # ë§Œë£Œëœ ë°ì´í„° ì‚­ì œ
                    del self.cache[key]
                    del self.timestamps[key]
            return None
    
    def set(self, key: str, data: RealTimeData):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        with self.lock:
            # ìºì‹œ í¬ê¸° ì œí•œ í™•ì¸
            if len(self.cache) >= self.max_size:
                # ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ
                oldest_key = min(self.timestamps.keys(), key=self.timestamps.get)
                del self.cache[oldest_key]
                del self.timestamps[oldest_key]
            
            self.cache[key] = data
            self.timestamps[key] = time.time()
    
    def clear(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        with self.lock:
            self.cache.clear()
            self.timestamps.clear()
    
    def get_stats(self) -> Dict:
        """ìºì‹œ í†µê³„"""
        with self.lock:
            return {
                'size': len(self.cache),
                'max_size': self.max_size,
                'hit_rate': 0,  # TODO: íˆíŠ¸ìœ¨ ê³„ì‚° êµ¬í˜„
                'ttl': self.ttl
            }

class RealTimeDataCollector:
    """ê³ ë„í™”ëœ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, config: DataCollectionConfig = None):
        self.config = config or DataCollectionConfig()
        
        # API ì´ˆê¸°í™”
        self.api = None
        self.api_lock = threading.Lock()
        
        # ë°ì´í„° í ë° ìºì‹œ
        self.data_queue = queue.Queue(maxsize=self.config.max_queue_size)
        self.cache = DataCache(max_size=1000, ttl=self.config.cache_duration)
        
        # ë°ì´í„° ì²˜ë¦¬ê¸°
        self.processor = DataProcessor()
        
        # êµ¬ë… ê´€ë¦¬
        self.subscribed_codes = set()
        self.subscription_lock = threading.Lock()
        
        # ì½œë°± ê´€ë¦¬
        self.callbacks = defaultdict(list)
        self.callback_lock = threading.Lock()
        
        # ìŠ¤ë ˆë“œ ê´€ë¦¬
        self.running = False
        self.collection_thread = None
        self.processing_thread = None
        self.monitoring_thread = None
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.stats = {
            'data_received': 0,
            'data_processed': 0,
            'errors': 0,
            'start_time': None,
            'last_update': None
        }
        
        # ì´ˆê¸°í™”
        self._initialize_api()
        
    def _initialize_api(self):
        """API ì´ˆê¸°í™”"""
        try:
            from PyQt5.QtWidgets import QApplication
            if not QApplication.instance():
                self.app = QApplication(sys.argv)
            else:
                self.app = QApplication.instance()
                
            self.api = KiwoomAPI()
            
            # ì‹¤ì‹œê°„ ë°ì´í„° ì½œë°± ì„¤ì •
            self.api.set_real_data_callback(self._on_real_data_received)
            
            logger.info("ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ê¸° API ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            handle_error(
                ErrorType.INITIALIZATION,
                "ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ê¸° API ì´ˆê¸°í™” ì‹¤íŒ¨",
                exception=e,
                error_level=ErrorLevel.CRITICAL
            )
            raise
    
    def start(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘"""
        if self.running:
            logger.warning("ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
            
        try:
            # API ë¡œê·¸ì¸
            if not self.api.login(timeout=30):
                raise Exception("API ë¡œê·¸ì¸ ì‹¤íŒ¨")
            
            self.running = True
            self.stats['start_time'] = datetime.now()
            
            # ìŠ¤ë ˆë“œ ì‹œì‘
            self.collection_thread = threading.Thread(target=self._collection_worker, daemon=True)
            self.processing_thread = threading.Thread(target=self._processing_worker, daemon=True)
            self.monitoring_thread = threading.Thread(target=self._monitoring_worker, daemon=True)
            
            self.collection_thread.start()
            self.processing_thread.start()
            self.monitoring_thread.start()
            
            logger.info("ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            
        except Exception as e:
            handle_error(
                ErrorType.INITIALIZATION,
                "ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì‹¤íŒ¨",
                exception=e,
                error_level=ErrorLevel.CRITICAL
            )
            raise
    
    def stop(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€"""
        if not self.running:
            return
            
        self.running = False
        
        # ëª¨ë“  êµ¬ë… í•´ì œ
        with self.subscription_lock:
            for code in list(self.subscribed_codes):
                try:
                    self.api.unsubscribe_real_data(code)
                except Exception as e:
                    logger.error(f"êµ¬ë… í•´ì œ ì‹¤íŒ¨: {code} - {e}")
            self.subscribed_codes.clear()
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.collection_thread:
            self.collection_thread.join(timeout=5)
        if self.processing_thread:
            self.processing_thread.join(timeout=5)
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        
        logger.info("ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€")
    
    def subscribe(self, codes: List[str]):
        """ì¢…ëª© êµ¬ë…"""
        with self.subscription_lock:
            for code in codes:
                if code not in self.subscribed_codes:
                    try:
                        self.api.subscribe_real_data(code)
                        self.subscribed_codes.add(code)
                        logger.info(f"ì¢…ëª© êµ¬ë…: {code}")
                    except Exception as e:
                        handle_error(
                            ErrorType.API,
                            f"ì¢…ëª© êµ¬ë… ì‹¤íŒ¨: {code}",
                            exception=e,
                            error_level=ErrorLevel.ERROR
                        )
    
    def unsubscribe(self, codes: List[str]):
        """ì¢…ëª© êµ¬ë… í•´ì œ"""
        with self.subscription_lock:
            for code in codes:
                if code in self.subscribed_codes:
                    try:
                        self.api.unsubscribe_real_data(code)
                        self.subscribed_codes.remove(code)
                        logger.info(f"ì¢…ëª© êµ¬ë… í•´ì œ: {code}")
                    except Exception as e:
                        handle_error(
                            ErrorType.API,
                            f"ì¢…ëª© êµ¬ë… í•´ì œ ì‹¤íŒ¨: {code}",
                            exception=e,
                            error_level=ErrorLevel.ERROR
                        )
    
    def add_callback(self, callback_type: str, callback: Callable):
        """ì½œë°± í•¨ìˆ˜ ë“±ë¡"""
        with self.callback_lock:
            self.callbacks[callback_type].append(callback)
    
    def remove_callback(self, callback_type: str, callback: Callable):
        """ì½œë°± í•¨ìˆ˜ ì œê±°"""
        with self.callback_lock:
            if callback_type in self.callbacks:
                try:
                    self.callbacks[callback_type].remove(callback)
                except ValueError:
                    pass
    
    def _on_real_data_received(self, code: str, data: Dict):
        """ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  ì²˜ë¦¬"""
        try:
            # RealTimeData ê°ì²´ ìƒì„±
            real_time_data = RealTimeData(
                code=code,
                name=data.get('name', ''),
                current_price=data.get('current_price', 0),
                change_rate=data.get('change_rate', 0),
                volume=data.get('volume', 0),
                amount=data.get('amount', 0),
                open_price=data.get('open_price', 0),
                high_price=data.get('high_price', 0),
                low_price=data.get('low_price', 0),
                prev_close=data.get('prev_close', 0),
                timestamp=datetime.now(),
                data_type='stock_tick',
                additional_data=data
            )
            
            # ìºì‹œì— ì €ì¥
            if self.config.enable_caching:
                self.cache.set(code, real_time_data)
            
            # íì— ì¶”ê°€
            try:
                self.data_queue.put_nowait(real_time_data)
                self.stats['data_received'] += 1
                self.stats['last_update'] = datetime.now()
            except queue.Full:
                logger.warning("ë°ì´í„° íê°€ ê°€ë“ ì°¼ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            handle_error(
                ErrorType.DATA_PROCESSING,
                f"ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  ì²˜ë¦¬ ì˜¤ë¥˜: {code}",
                exception=e,
                error_level=ErrorLevel.ERROR
            )
            self.stats['errors'] += 1
    
    def _collection_worker(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # API ìƒíƒœ í™•ì¸
                if not self.api.is_connected():
                    logger.warning("API ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤. ì¬ì—°ê²° ì‹œë„...")
                    self._reconnect_api()
                
                time.sleep(self.config.update_interval)
                
            except Exception as e:
                handle_error(
                    ErrorType.API,
                    "ë°ì´í„° ìˆ˜ì§‘ ì›Œì»¤ ì˜¤ë¥˜",
                    exception=e,
                    error_level=ErrorLevel.ERROR
                )
                time.sleep(5)
    
    def _processing_worker(self):
        """ë°ì´í„° ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # íì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                try:
                    data = self.data_queue.get(timeout=1)
                except queue.Empty:
                    continue
                
                # ë°ì´í„° ì²˜ë¦¬
                processed_data = self.processor.process_data(data)
                
                # ì½œë°± í˜¸ì¶œ
                with self.callback_lock:
                    for callback in self.callbacks.get('data_processed', []):
                        try:
                            callback(data, processed_data)
                        except Exception as e:
                            logger.error(f"ì½œë°± ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                
                self.stats['data_processed'] += 1
                
            except Exception as e:
                handle_error(
                    ErrorType.DATA_PROCESSING,
                    "ë°ì´í„° ì²˜ë¦¬ ì›Œì»¤ ì˜¤ë¥˜",
                    exception=e,
                    error_level=ErrorLevel.ERROR
                )
                self.stats['errors'] += 1
    
    def _monitoring_worker(self):
        """ëª¨ë‹ˆí„°ë§ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # ì„±ëŠ¥ í†µê³„ ê¸°ë¡
                if self.config.enable_monitoring:
                    record_data_processed(
                        data_count=self.stats['data_processed'],
                        error_count=self.stats['errors']
                    )
                
                # í†µê³„ ë¡œê¹…
                if self.stats['data_processed'] % 100 == 0:
                    logger.info(f"ë°ì´í„° ì²˜ë¦¬ í†µê³„: ìˆ˜ì‹ ={self.stats['data_received']}, "
                              f"ì²˜ë¦¬={self.stats['data_processed']}, ì˜¤ë¥˜={self.stats['errors']}")
                
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ëª¨ë‹ˆí„°ë§
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì›Œì»¤ ì˜¤ë¥˜: {e}")
                time.sleep(60)
    
    def _reconnect_api(self):
        """API ì¬ì—°ê²°"""
        try:
            with self.api_lock:
                if self.api.login(timeout=30):
                    # êµ¬ë… ë³µì›
                    with self.subscription_lock:
                        for code in self.subscribed_codes:
                            try:
                                self.api.subscribe_real_data(code)
                            except Exception as e:
                                logger.error(f"êµ¬ë… ë³µì› ì‹¤íŒ¨: {code} - {e}")
                    logger.info("API ì¬ì—°ê²° ì„±ê³µ")
                else:
                    logger.error("API ì¬ì—°ê²° ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"API ì¬ì—°ê²° ì˜¤ë¥˜: {e}")
    
    def get_data(self, code: str) -> Optional[RealTimeData]:
        """íŠ¹ì • ì¢…ëª©ì˜ ìµœì‹  ë°ì´í„° ì¡°íšŒ"""
        return self.cache.get(code)
    
    def get_all_data(self) -> Dict[str, RealTimeData]:
        """ëª¨ë“  ì¢…ëª©ì˜ ìµœì‹  ë°ì´í„° ì¡°íšŒ"""
        return self.cache.cache.copy()
    
    def get_stats(self) -> Dict:
        """ìˆ˜ì§‘ê¸° í†µê³„ ì¡°íšŒ"""
        stats = self.stats.copy()
        stats.update({
            'subscribed_count': len(self.subscribed_codes),
            'queue_size': self.data_queue.qsize(),
            'cache_stats': self.cache.get_stats(),
            'running': self.running
        })
        return stats
    
    def export_data(self, filename: str, format: str = 'csv'):
        """ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        try:
            all_data = self.get_all_data()
            if not all_data:
                logger.warning("ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return
            
            data_list = []
            for code, data in all_data.items():
                data_dict = asdict(data)
                data_dict['timestamp'] = data.timestamp.isoformat()
                data_list.append(data_dict)
            
            df = pd.DataFrame(data_list)
            
            if format.lower() == 'csv':
                df.to_csv(filename, index=False, encoding='utf-8-sig')
            elif format.lower() == 'json':
                df.to_json(filename, orient='records', force_ascii=False, indent=2)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
            
            logger.info(f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filename}")
            
        except Exception as e:
            handle_error(
                ErrorType.DATA_EXPORT,
                f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {filename}",
                exception=e,
                error_level=ErrorLevel.ERROR
            )

class RealTimeDataAnalyzer:
    """ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ê¸°"""
    
    def __init__(self, collector: RealTimeDataCollector):
        self.collector = collector
        self.analysis_results = {}
        self.analysis_lock = threading.Lock()
        
    def analyze_market_trend(self) -> Dict:
        """ì‹œì¥ ì „ì²´ ì¶”ì„¸ ë¶„ì„"""
        try:
            all_data = self.collector.get_all_data()
            if not all_data:
                return {}
            
            # ìƒìŠ¹/í•˜ë½ ì¢…ëª© ìˆ˜ ê³„ì‚°
            up_count = sum(1 for data in all_data.values() if data.change_rate > 0)
            down_count = sum(1 for data in all_data.values() if data.change_rate < 0)
            flat_count = len(all_data) - up_count - down_count
            
            # í‰ê·  ë“±ë½ë¥ 
            avg_change_rate = np.mean([data.change_rate for data in all_data.values()])
            
            # ê±°ë˜ëŸ‰ ë¶„ì„
            total_volume = sum(data.volume for data in all_data.values())
            avg_volume = total_volume / len(all_data) if all_data else 0
            
            return {
                'up_count': up_count,
                'down_count': down_count,
                'flat_count': flat_count,
                'avg_change_rate': avg_change_rate,
                'total_volume': total_volume,
                'avg_volume': avg_volume,
                'market_sentiment': 'bullish' if avg_change_rate > 0.5 else 'bearish' if avg_change_rate < -0.5 else 'neutral'
            }
            
        except Exception as e:
            handle_error(
                ErrorType.DATA_ANALYSIS,
                "ì‹œì¥ ì¶”ì„¸ ë¶„ì„ ì˜¤ë¥˜",
                exception=e,
                error_level=ErrorLevel.ERROR
            )
            return {}
    
    def find_hot_stocks(self, min_change_rate: float = 3.0) -> List[Dict]:
        """ê¸‰ë“±/ê¸‰ë½ ì¢…ëª© ì°¾ê¸°"""
        try:
            all_data = self.collector.get_all_data()
            hot_stocks = []
            
            for code, data in all_data.items():
                if abs(data.change_rate) >= min_change_rate:
                    hot_stocks.append({
                        'code': code,
                        'name': data.name,
                        'change_rate': data.change_rate,
                        'current_price': data.current_price,
                        'volume': data.volume,
                        'type': 'up' if data.change_rate > 0 else 'down'
                    })
            
            # ë“±ë½ë¥  ê¸°ì¤€ ì •ë ¬
            hot_stocks.sort(key=lambda x: abs(x['change_rate']), reverse=True)
            
            return hot_stocks
            
        except Exception as e:
            handle_error(
                ErrorType.DATA_ANALYSIS,
                "ê¸‰ë“±/ê¸‰ë½ ì¢…ëª© ë¶„ì„ ì˜¤ë¥˜",
                exception=e,
                error_level=ErrorLevel.ERROR
            )
            return []
    
    def calculate_correlation(self, codes: List[str]) -> Dict:
        """ì¢…ëª© ê°„ ìƒê´€ê´€ê³„ ê³„ì‚°"""
        try:
            all_data = self.collector.get_all_data()
            available_codes = [code for code in codes if code in all_data]
            
            if len(available_codes) < 2:
                return {}
            
            # ë“±ë½ë¥  ë°ì´í„° ì¶”ì¶œ
            change_rates = {}
            for code in available_codes:
                change_rates[code] = all_data[code].change_rate
            
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation_matrix = {}
            for i, code1 in enumerate(available_codes):
                correlation_matrix[code1] = {}
                for code2 in available_codes:
                    if code1 == code2:
                        correlation_matrix[code1][code2] = 1.0
                    else:
                        # ê°„ë‹¨í•œ ìƒê´€ê´€ê³„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ì‹œê³„ì—´ ë°ì´í„° í•„ìš”)
                        correlation_matrix[code1][code2] = 0.0
            
            return correlation_matrix
            
        except Exception as e:
            handle_error(
                ErrorType.DATA_ANALYSIS,
                "ìƒê´€ê´€ê³„ ê³„ì‚° ì˜¤ë¥˜",
                exception=e,
                error_level=ErrorLevel.ERROR
            )
            return {}

def main():
    """ë©”ì¸ í•¨ìˆ˜ - í…ŒìŠ¤íŠ¸ìš©"""
    try:
        # ì„¤ì •
        config = DataCollectionConfig(
            update_interval=1.0,
            max_queue_size=5000,
            cache_duration=300,
            enable_monitoring=True
        )
        
        # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        collector = RealTimeDataCollector(config)
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = RealTimeDataAnalyzer(collector)
        
        # ì½œë°± ë“±ë¡
        def on_data_processed(data, processed_data):
            print(f"ğŸ“Š {data.code} - {data.current_price:,}ì› ({data.change_rate:+.2f}%)")
        
        collector.add_callback('data_processed', on_data_processed)
        
        # í…ŒìŠ¤íŠ¸ ì¢…ëª© êµ¬ë…
        test_codes = ['005930', '000660', '035420']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, NAVER
        collector.subscribe(test_codes)
        
        # ìˆ˜ì§‘ ì‹œì‘
        collector.start()
        
        print("ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        print("Ctrl+Cë¡œ ì¤‘ë‹¨")
        
        # 30ì´ˆê°„ ì‹¤í–‰
        time.sleep(30)
        
        # í†µê³„ ì¶œë ¥
        stats = collector.get_stats()
        print(f"\nğŸ“ˆ ìˆ˜ì§‘ í†µê³„:")
        print(f"   ìˆ˜ì‹  ë°ì´í„°: {stats['data_received']}")
        print(f"   ì²˜ë¦¬ ë°ì´í„°: {stats['data_processed']}")
        print(f"   ì˜¤ë¥˜: {stats['errors']}")
        
        # ì‹œì¥ ë¶„ì„
        market_trend = analyzer.analyze_market_trend()
        print(f"\nğŸ“Š ì‹œì¥ ë¶„ì„:")
        print(f"   ìƒìŠ¹: {market_trend.get('up_count', 0)}ê°œ")
        print(f"   í•˜ë½: {market_trend.get('down_count', 0)}ê°œ")
        print(f"   í‰ê·  ë“±ë½ë¥ : {market_trend.get('avg_change_rate', 0):+.2f}%")
        
        # ê¸‰ë“±/ê¸‰ë½ ì¢…ëª©
        hot_stocks = analyzer.find_hot_stocks(min_change_rate=2.0)
        if hot_stocks:
            print(f"\nğŸ”¥ ê¸‰ë“±/ê¸‰ë½ ì¢…ëª©:")
            for stock in hot_stocks[:5]:
                print(f"   {stock['code']} {stock['name']}: {stock['change_rate']:+.2f}%")
        
        # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        collector.export_data('real_time_data_export.csv', 'csv')
        
        # ì •ë¦¬
        collector.stop()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        collector.stop()
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        collector.stop()

if __name__ == "__main__":
    main() 